{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 11:35:41.010824: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-21 11:35:41.025669: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-21 11:35:41.072618: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-21 11:35:41.151043: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-21 11:35:41.173799: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-21 11:35:41.227736: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-21 11:35:45.078555: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense  \n",
    "from sensor.components.prepare_base_model import PrepareBaseModel\n",
    "from sensor.config.configuration import Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "preprocessed_data_path = '/home/moraa/Documents/Machine-learning/Gas_Sensor/artifacts/preprocessed/preprocessed_data.csv'\n",
    "data = pd.read_csv(preprocessed_data_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_120</th>\n",
       "      <th>feature_121</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041799</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.014905</td>\n",
       "      <td>0.014487</td>\n",
       "      <td>0.008184</td>\n",
       "      <td>0.987431</td>\n",
       "      <td>0.900444</td>\n",
       "      <td>0.928613</td>\n",
       "      <td>0.031268</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962156</td>\n",
       "      <td>0.161350</td>\n",
       "      <td>0.047297</td>\n",
       "      <td>0.063982</td>\n",
       "      <td>0.010069</td>\n",
       "      <td>0.026855</td>\n",
       "      <td>0.954190</td>\n",
       "      <td>0.863092</td>\n",
       "      <td>0.965217</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055265</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.028482</td>\n",
       "      <td>0.029074</td>\n",
       "      <td>0.010944</td>\n",
       "      <td>0.976104</td>\n",
       "      <td>0.893223</td>\n",
       "      <td>0.927153</td>\n",
       "      <td>0.096176</td>\n",
       "      <td>0.004339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947623</td>\n",
       "      <td>0.255568</td>\n",
       "      <td>0.081593</td>\n",
       "      <td>0.192538</td>\n",
       "      <td>0.038253</td>\n",
       "      <td>0.074540</td>\n",
       "      <td>0.863947</td>\n",
       "      <td>0.798812</td>\n",
       "      <td>0.950068</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.043564</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.016421</td>\n",
       "      <td>0.015901</td>\n",
       "      <td>0.008389</td>\n",
       "      <td>0.986289</td>\n",
       "      <td>0.899999</td>\n",
       "      <td>0.929645</td>\n",
       "      <td>0.093692</td>\n",
       "      <td>0.003431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962320</td>\n",
       "      <td>0.163915</td>\n",
       "      <td>0.046742</td>\n",
       "      <td>0.065451</td>\n",
       "      <td>0.010427</td>\n",
       "      <td>0.028752</td>\n",
       "      <td>0.951795</td>\n",
       "      <td>0.862188</td>\n",
       "      <td>0.964740</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.047366</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.020077</td>\n",
       "      <td>0.009042</td>\n",
       "      <td>0.982702</td>\n",
       "      <td>0.895460</td>\n",
       "      <td>0.928534</td>\n",
       "      <td>0.088094</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.943240</td>\n",
       "      <td>0.254046</td>\n",
       "      <td>0.078096</td>\n",
       "      <td>0.190584</td>\n",
       "      <td>0.037645</td>\n",
       "      <td>0.075604</td>\n",
       "      <td>0.867341</td>\n",
       "      <td>0.797939</td>\n",
       "      <td>0.950448</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048150</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>0.020313</td>\n",
       "      <td>0.018990</td>\n",
       "      <td>0.008770</td>\n",
       "      <td>0.983502</td>\n",
       "      <td>0.897631</td>\n",
       "      <td>0.928644</td>\n",
       "      <td>0.104930</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963530</td>\n",
       "      <td>0.163810</td>\n",
       "      <td>0.048934</td>\n",
       "      <td>0.063296</td>\n",
       "      <td>0.010180</td>\n",
       "      <td>0.027341</td>\n",
       "      <td>0.952082</td>\n",
       "      <td>0.862766</td>\n",
       "      <td>0.965510</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.041799   0.002133   0.014905   0.014487   0.008184   0.987431   \n",
       "1   0.055265   0.003087   0.028482   0.029074   0.010944   0.976104   \n",
       "2   0.043564   0.002277   0.016421   0.015901   0.008389   0.986289   \n",
       "3   0.047366   0.002547   0.020202   0.020077   0.009042   0.982702   \n",
       "4   0.048150   0.002544   0.020313   0.018990   0.008770   0.983502   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_120  feature_121  \\\n",
       "0   0.900444   0.928613   0.031268    0.000582  ...     0.962156     0.161350   \n",
       "1   0.893223   0.927153   0.096176    0.004339  ...     0.947623     0.255568   \n",
       "2   0.899999   0.929645   0.093692    0.003431  ...     0.962320     0.163915   \n",
       "3   0.895460   0.928534   0.088094    0.002201  ...     0.943240     0.254046   \n",
       "4   0.897631   0.928644   0.104930    0.003572  ...     0.963530     0.163810   \n",
       "\n",
       "   feature_122  feature_123  feature_124  feature_125  feature_126  \\\n",
       "0     0.047297     0.063982     0.010069     0.026855     0.954190   \n",
       "1     0.081593     0.192538     0.038253     0.074540     0.863947   \n",
       "2     0.046742     0.065451     0.010427     0.028752     0.951795   \n",
       "3     0.078096     0.190584     0.037645     0.075604     0.867341   \n",
       "4     0.048934     0.063296     0.010180     0.027341     0.952082   \n",
       "\n",
       "   feature_127  feature_128  target  \n",
       "0     0.863092     0.965217       5  \n",
       "1     0.798812     0.950068       4  \n",
       "2     0.862188     0.964740       5  \n",
       "3     0.797939     0.950448       4  \n",
       "4     0.862766     0.965510       5  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11128, 128) (11128, 6)\n",
      "(2782, 128) (2782, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('/home/moraa/Documents/Machine-learning/Gas_Sensor/artifacts/preprocessed/preprocessed_data.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# One-Hot Encoding the target variable\n",
    "encoder = OneHotEncoder(sparse_output=False)  # Use sparse_output for newer versions\n",
    "y_encoded = encoder.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check shapes\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-21 11:35:53,350: INFO: configuration: Reading configuration file from /home/moraa/Documents/Machine-learning/Gas_Sensor/config/config.yaml]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moraa/Documents/Machine-learning/Gas_Sensor/venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.3235 - loss: 1.5734 - val_accuracy: 0.6685 - val_loss: 0.8471\n",
      "Epoch 2/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6930 - loss: 0.8087 - val_accuracy: 0.7812 - val_loss: 0.5175\n",
      "Epoch 3/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8079 - loss: 0.5467 - val_accuracy: 0.8657 - val_loss: 0.3278\n",
      "Epoch 4/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8554 - loss: 0.4274 - val_accuracy: 0.9057 - val_loss: 0.2616\n",
      "Epoch 5/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8705 - loss: 0.3776 - val_accuracy: 0.9425 - val_loss: 0.2190\n",
      "Epoch 6/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8758 - loss: 0.3786 - val_accuracy: 0.8841 - val_loss: 0.3275\n",
      "Epoch 7/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8983 - loss: 0.3166 - val_accuracy: 0.9632 - val_loss: 0.1667\n",
      "Epoch 8/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9120 - loss: 0.2721 - val_accuracy: 0.9510 - val_loss: 0.1830\n",
      "Epoch 9/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9076 - loss: 0.2814 - val_accuracy: 0.9708 - val_loss: 0.1368\n",
      "Epoch 10/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9188 - loss: 0.2383 - val_accuracy: 0.9510 - val_loss: 0.1543\n",
      "Epoch 11/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9280 - loss: 0.2343 - val_accuracy: 0.9717 - val_loss: 0.1303\n",
      "Epoch 12/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9290 - loss: 0.2231 - val_accuracy: 0.9704 - val_loss: 0.1250\n",
      "Epoch 13/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9310 - loss: 0.2180 - val_accuracy: 0.9730 - val_loss: 0.1049\n",
      "Epoch 14/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9297 - loss: 0.2170 - val_accuracy: 0.9461 - val_loss: 0.1813\n",
      "Epoch 15/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9195 - loss: 0.2406 - val_accuracy: 0.9182 - val_loss: 0.2368\n",
      "Epoch 16/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9184 - loss: 0.2540 - val_accuracy: 0.9726 - val_loss: 0.1011\n",
      "Epoch 17/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9435 - loss: 0.1819 - val_accuracy: 0.9659 - val_loss: 0.1180\n",
      "Epoch 18/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9345 - loss: 0.1980 - val_accuracy: 0.9708 - val_loss: 0.1082\n",
      "Epoch 19/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9468 - loss: 0.1715 - val_accuracy: 0.9389 - val_loss: 0.1496\n",
      "Epoch 20/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9422 - loss: 0.1791 - val_accuracy: 0.9753 - val_loss: 0.1039\n",
      "Epoch 21/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9334 - loss: 0.2049 - val_accuracy: 0.9596 - val_loss: 0.1329\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "\n",
    "# Load the configuration\n",
    "config = Configuration()\n",
    "model_config = config.get_model_config()\n",
    "\n",
    "# Load the prepared model\n",
    "model_path = '/home/moraa/Documents/Machine-learning/Gas_Sensor/artifacts/prepared_model/gas_classification_model.keras'\n",
    "prepare_model = PrepareBaseModel(config=model_config)\n",
    "\n",
    "# Load the model from the saved path\n",
    "prepare_model.model = load_model(model_path)\n",
    "\n",
    "# Assuming X_train and y_train are defined and y_train is one-hot encoded\n",
    "# Train the model\n",
    "history = prepare_model.model.fit(X_train, y_train, \n",
    "                                   validation_split=0.2, \n",
    "                                   epochs=100, \n",
    "                                   batch_size=32, \n",
    "                                   callbacks=[EarlyStopping(patience=5, restore_best_weights=True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
