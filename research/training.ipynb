{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 17:10:19.313990: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-16 17:10:19.319350: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-16 17:10:19.333543: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750083019.354626  179433 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750083019.361192  179433 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750083019.376820  179433 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750083019.376843  179433 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750083019.376845  179433 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750083019.376847  179433 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-16 17:10:19.381928: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense  \n",
    "from sensor.components.prepare_base_model import PrepareBaseModel\n",
    "from sensor.config.configuration import Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "preprocessed_data_path = '/home/moraa-ontita/Documents/Machine-learning/Gas_Sensor/artifacts/preprocessed/notebook_preprocessed.csv'\n",
    "data = pd.read_csv(preprocessed_data_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_120</th>\n",
       "      <th>feature_121</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.676157</td>\n",
       "      <td>0.658295</td>\n",
       "      <td>0.722534</td>\n",
       "      <td>0.756207</td>\n",
       "      <td>0.727536</td>\n",
       "      <td>0.302161</td>\n",
       "      <td>0.071278</td>\n",
       "      <td>0.103377</td>\n",
       "      <td>0.649085</td>\n",
       "      <td>0.496269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131901</td>\n",
       "      <td>0.573114</td>\n",
       "      <td>0.500836</td>\n",
       "      <td>0.666088</td>\n",
       "      <td>0.553585</td>\n",
       "      <td>0.683751</td>\n",
       "      <td>0.429972</td>\n",
       "      <td>0.106052</td>\n",
       "      <td>0.135831</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.502643</td>\n",
       "      <td>0.516996</td>\n",
       "      <td>0.563249</td>\n",
       "      <td>0.629137</td>\n",
       "      <td>0.626112</td>\n",
       "      <td>0.605105</td>\n",
       "      <td>0.087501</td>\n",
       "      <td>0.114002</td>\n",
       "      <td>0.462891</td>\n",
       "      <td>0.361376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164178</td>\n",
       "      <td>0.329639</td>\n",
       "      <td>0.312260</td>\n",
       "      <td>0.515481</td>\n",
       "      <td>0.482845</td>\n",
       "      <td>0.612832</td>\n",
       "      <td>0.737153</td>\n",
       "      <td>0.163046</td>\n",
       "      <td>0.169744</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.674979</td>\n",
       "      <td>0.703586</td>\n",
       "      <td>0.696306</td>\n",
       "      <td>0.718099</td>\n",
       "      <td>0.693556</td>\n",
       "      <td>0.346455</td>\n",
       "      <td>0.052010</td>\n",
       "      <td>0.095141</td>\n",
       "      <td>0.678156</td>\n",
       "      <td>0.584185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125351</td>\n",
       "      <td>0.637336</td>\n",
       "      <td>0.652883</td>\n",
       "      <td>0.722456</td>\n",
       "      <td>0.593954</td>\n",
       "      <td>0.722695</td>\n",
       "      <td>0.412082</td>\n",
       "      <td>0.099673</td>\n",
       "      <td>0.126608</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.380613</td>\n",
       "      <td>0.390597</td>\n",
       "      <td>0.332772</td>\n",
       "      <td>0.515395</td>\n",
       "      <td>0.601823</td>\n",
       "      <td>0.803248</td>\n",
       "      <td>0.104949</td>\n",
       "      <td>0.117789</td>\n",
       "      <td>0.372752</td>\n",
       "      <td>0.272514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169882</td>\n",
       "      <td>0.241707</td>\n",
       "      <td>0.196775</td>\n",
       "      <td>0.210215</td>\n",
       "      <td>0.195645</td>\n",
       "      <td>0.360144</td>\n",
       "      <td>0.866871</td>\n",
       "      <td>0.183067</td>\n",
       "      <td>0.177099</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.730503</td>\n",
       "      <td>0.714337</td>\n",
       "      <td>0.772236</td>\n",
       "      <td>0.802591</td>\n",
       "      <td>0.751103</td>\n",
       "      <td>0.238953</td>\n",
       "      <td>0.063224</td>\n",
       "      <td>0.096749</td>\n",
       "      <td>0.705728</td>\n",
       "      <td>0.557537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113260</td>\n",
       "      <td>0.704145</td>\n",
       "      <td>0.633166</td>\n",
       "      <td>0.759772</td>\n",
       "      <td>0.586982</td>\n",
       "      <td>0.710484</td>\n",
       "      <td>0.287408</td>\n",
       "      <td>0.072757</td>\n",
       "      <td>0.119156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.676157   0.658295   0.722534   0.756207   0.727536   0.302161   \n",
       "1   0.502643   0.516996   0.563249   0.629137   0.626112   0.605105   \n",
       "2   0.674979   0.703586   0.696306   0.718099   0.693556   0.346455   \n",
       "3   0.380613   0.390597   0.332772   0.515395   0.601823   0.803248   \n",
       "4   0.730503   0.714337   0.772236   0.802591   0.751103   0.238953   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_120  feature_121  \\\n",
       "0   0.071278   0.103377   0.649085    0.496269  ...     0.131901     0.573114   \n",
       "1   0.087501   0.114002   0.462891    0.361376  ...     0.164178     0.329639   \n",
       "2   0.052010   0.095141   0.678156    0.584185  ...     0.125351     0.637336   \n",
       "3   0.104949   0.117789   0.372752    0.272514  ...     0.169882     0.241707   \n",
       "4   0.063224   0.096749   0.705728    0.557537  ...     0.113260     0.704145   \n",
       "\n",
       "   feature_122  feature_123  feature_124  feature_125  feature_126  \\\n",
       "0     0.500836     0.666088     0.553585     0.683751     0.429972   \n",
       "1     0.312260     0.515481     0.482845     0.612832     0.737153   \n",
       "2     0.652883     0.722456     0.593954     0.722695     0.412082   \n",
       "3     0.196775     0.210215     0.195645     0.360144     0.866871   \n",
       "4     0.633166     0.759772     0.586982     0.710484     0.287408   \n",
       "\n",
       "   feature_127  feature_128  target  \n",
       "0     0.106052     0.135831       1  \n",
       "1     0.163046     0.169744       1  \n",
       "2     0.099673     0.126608       2  \n",
       "3     0.183067     0.177099       2  \n",
       "4     0.072757     0.119156       1  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11128, 128) (11128, 6)\n",
      "(2782, 128) (2782, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# One-Hot Encoding the target variable\n",
    "encoder = OneHotEncoder(sparse_output=False)  # Use sparse_output for newer versions\n",
    "y_encoded = encoder.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check shapes\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 17:11:06,898: INFO: configuration: Reading configuration file from config/config.yaml]\n",
      "[2025-06-16 17:11:06,902: INFO: configuration: Reading configuration file from param.yaml]\n",
      "[2025-06-16 17:11:06,904: INFO: configuration: Model config data: {'input_shape': [128], 'save_dir': 'artifacts/prepared_model/', 'optimizer': 'adam', 'classification_loss': 'categorical_crossentropy', 'drift_loss': 'mean_squared_error', 'classification_metric': 'accuracy', 'drift_metric': 'mse'}, Type: <class 'dict'>]\n",
      "[2025-06-16 17:11:06,905: INFO: prepare_base_model: PrepareBaseModel initialized with configuration.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 17:11:06.911091: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "/home/moraa-ontita/Documents/Machine-learning/Gas_Sensor/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1812 - loss: nan - val_accuracy: 0.1815 - val_loss: nan\n",
      "Epoch 2/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1872 - loss: nan - val_accuracy: 0.1815 - val_loss: nan\n",
      "Epoch 3/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1893 - loss: nan - val_accuracy: 0.1815 - val_loss: nan\n",
      "Epoch 4/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1872 - loss: nan - val_accuracy: 0.1815 - val_loss: nan\n",
      "Epoch 5/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1909 - loss: nan - val_accuracy: 0.1815 - val_loss: nan\n",
      "Epoch 6/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1849 - loss: nan - val_accuracy: 0.1815 - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "\n",
    "os.chdir(\"/home/moraa-ontita/Documents/Machine-learning/Gas_Sensor\")\n",
    "\n",
    "# Load the configuration\n",
    "config = Configuration()\n",
    "model_config = config.get_model_config()\n",
    "\n",
    "# Load the prepared model\n",
    "model_path = '/home/moraa-ontita/Documents/Machine-learning/Gas_Sensor/artifacts/prepared_model/gas_classification_model.keras'\n",
    "prepare_model = PrepareBaseModel(config=model_config)\n",
    "\n",
    "# Load the model from the saved path\n",
    "prepare_model.model = load_model(model_path)\n",
    "\n",
    "# Assuming X_train and y_train are defined and y_train is one-hot encoded\n",
    "# Train the model\n",
    "history = prepare_model.model.fit(X_train, y_train, \n",
    "                                   validation_split=0.2, \n",
    "                                   epochs=100, \n",
    "                                   batch_size=32, \n",
    "                                   callbacks=[EarlyStopping(patience=5, restore_best_weights=True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
